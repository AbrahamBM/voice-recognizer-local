# Voice Recognizer Local

Sistema de reconocimiento de voz offline completo que funciona sin conexiÃ³n a internet. Este proyecto simula un asistente de voz con reconocimiento de voz, comprensiÃ³n de lenguaje natural, ejecuciÃ³n de acciones y sÃ­ntesis de voz.

## DescripciÃ³n

Voice Recognizer Local es un sistema de asistente de voz que integra:
- **ASR (Automatic Speech Recognition)**: Reconocimiento de voz usando Vosk
- **NLU (Natural Language Understanding)**: ComprensiÃ³n de intenciones basada en reglas
- **Executor**: EjecuciÃ³n de acciones simuladas
- **TTS (Text-to-Speech)**: SÃ­ntesis de voz usando pyttsx3

## Estructura del Proyecto

```
voice-recognizer-local/
â”œâ”€â”€ README.md                         # Contexto del proyecto y guÃ­a de uso
â”œâ”€â”€ requirements.txt                  # Dependencias de Python necesarias
â”œâ”€â”€ examples/                         # Ejemplos y audios de prueba
â”œâ”€â”€ logs/                             # Carpeta de logs generados por la app
â”‚   â””â”€â”€ transcriptions.log            # Historial de transcripciones
â”œâ”€â”€ models/                           # Modelos Vosk descargados localmente
â”‚   â””â”€â”€ vosk-model-small-es-0.42/     # Modelo espaÃ±ol ejemplo
â”‚       â”œâ”€â”€ am/                       # ParÃ¡metros acÃºsticos
â”‚       â”œâ”€â”€ conf/                     # ConfiguraciÃ³n del modelo
â”‚       â”œâ”€â”€ graph/                    # Grafos FST para decodificaciÃ³n
â”‚       â”œâ”€â”€ ivector/                  # Configs y matrices de i-vectors
â”‚       â””â”€â”€ README                    # Notas del modelo
â”œâ”€â”€ src/                              # CÃ³digo fuente del asistente
â”‚   â”œâ”€â”€ __init__.py                   # Marca el paquete Python
â”‚   â”œâ”€â”€ main.py                       # Punto de entrada de la app
â”‚   â”œâ”€â”€ asr/                          # MÃ³dulo de reconocimiento de voz (ASR)
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ vosk_asr.py               # IntegraciÃ³n con Vosk para ASR
â”‚   â”œâ”€â”€ executor/                     # Ejecutor de acciones segÃºn intenciÃ³n
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ actions.py                # Acciones simuladas (encender/apagar, etc.)
â”‚   â”œâ”€â”€ logs/                         # Utilidades o datos de logging internos
â”‚   â”œâ”€â”€ nlu/                          # ComprensiÃ³n de lenguaje natural (NLU)
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ matcher.py                # Reglas/patrones para detectar intenciones
â”‚   â”œâ”€â”€ tts/                          # SÃ­ntesis de voz (TTS)
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ tts_engine.py             # Engine de TTS con pyttsx3
â”‚   â””â”€â”€ utils/                        # Utilidades compartidas
â”‚       â”œâ”€â”€ __init__.py
â”‚       â””â”€â”€ audio.py                  # GrabaciÃ³n/procesamiento bÃ¡sico de audio
â””â”€â”€ tests/                            # Suite de pruebas
    â”œâ”€â”€ test_actions.py               # Tests de acciones del ejecutor
    â””â”€â”€ test_matcher.py               # Tests del NLU (matcher)
```

## ðŸ”§ SimulaciÃ³n en TinkerCad

Este proyecto incluye una representaciÃ³n fÃ­sica simulada que permite visualizar el funcionamiento del sistema mediante componentes Arduino. Cada mÃ³dulo del software estÃ¡ representado por un LED que se ilumina durante su ejecuciÃ³n, permitiendo observar el flujo completo del procesamiento de voz.

**ðŸ”— [Ver SimulaciÃ³n en TinkerCad](https://www.tinkercad.com/things/aPTMwrCgVry-pia-micro-lab?sharecode=rPbKNDZp1P1STcpVJYrVdIy9z66ohUe5sYGmHNuM6B8)**

### CaracterÃ­sticas de la SimulaciÃ³n

- **VisualizaciÃ³n en tiempo real**: LEDs de colores representan cada etapa del proceso
- **Interfaz LCD**: Muestra el estado actual y respuestas del sistema  
- **Entrada interactiva**: Botones y potenciÃ³metro simulan comandos de voz
- **Audio simulado**: Buzzer representa la sÃ­ntesis de voz

### Componentes Representados

| LED | MÃ³dulo del Sistema |
|-----|-------------------|
| ðŸ”´ Rojo | Captura de Audio |
| ðŸŸ¡ Amarillo | Reconocimiento ASR (Vosk) |
| ðŸŸ¢ Verde | AnÃ¡lisis NLU |
| ðŸ”µ Azul | EjecuciÃ³n de Acciones |
| âšª Blanco | SÃ­ntesis de Voz (TTS) |

Para mÃ¡s detalles sobre la implementaciÃ³n en hardware, consulta la carpeta `/tinkercad` en el repositorio.

## InstalaciÃ³n

### 1. Prerrequisitos

- Python 3.8 o superior
- Microphone (opcional, para reconocimiento de voz en vivo)
- Sistema operativo: Windows, macOS, o Linux

### 2. Clonar o descargar el proyecto

```bash
cd voice-recognizer-local
```

### 3. Instalar dependencias

```bash
pip install -r requirements.txt
```

### 4. Descargar modelo de Vosk (Opcional pero recomendado)

Para reconocimiento de voz, necesitas descargar un modelo de Vosk:

1. Visita [https://alphacephei.com/vosk/models](https://alphacephei.com/vosk/models)
2. Descarga un modelo (recomendado: `vosk-model-small-es-0.42` para espaÃ±ol o `vosk-model-small-en-us-0.15` para inglÃ©s)
3. Extrae el modelo en la carpeta `models/`

**Ejemplo:**
```bash
# Para espaÃ±ol
cd models
# Descargar y extraer modelo espaÃ±ol
# Estructura esperada: models/vosk-model-small-es-0.42/
```

### 5. Verificar instalaciÃ³n

```bash
# Ejecutar tests
pytest tests/ -v
```

## Uso

### Modo Interactivo

Ejecuta el asistente en modo interactivo:

```bash
python src/main.py
```

El programa te pedirÃ¡ que presiones Enter para empezar a grabar. Di uno de estos comandos:
- "hola" o "saludos" - Saludo
- "quÃ© hora es" - Consultar hora
- "enciende la luz" - Encender luz
- "apaga la luz" - Apagar luz

### Uso ProgramÃ¡tico

```python
from src.main import VoiceRecognizer

# Inicializar
recognizer = VoiceRecognizer(model_path="models")

# Procesar comando de voz
recognizer.process_command(duration=3.0)

# O procesar texto directamente
response = recognizer.process_text("quÃ© hora es")
print(response)
```

### Reconocimiento desde Archivo

```python
from src.asr.vosk_asr import VoskASR

asr = VoskASR(model_path="models")
text = asr.recognize_from_file("examples/sample.wav")
print(text)
```

## Tests

Ejecutar todos los tests:

```bash
pytest tests/ -v
```

Ejecutar tests especÃ­ficos:

```bash
pytest tests/test_matcher.py -v
pytest tests/test_actions.py -v
```

## Intenciones Soportadas

El sistema reconoce las siguientes intenciones:

| Intent | Ejemplos | AcciÃ³n |
|--------|----------|--------|
| `saludo` | "hola", "saludos", "hi" | Responder con saludo |
| `hora` | "quÃ© hora es", "dime la hora" | Mostrar hora actual |
| `encender_luz` | "enciende la luz", "prende la luz" | Simular encender luz |
| `apagar_luz` | "apaga la luz", "apagar luz" | Simular apagar luz |

## PersonalizaciÃ³n

### Agregar Nueva IntenciÃ³n

1. Edita `src/nlu/matcher.py` y agrega el patrÃ³n:

```python
nueva_intencion_patterns = [
    r'\b(palabra|clave)\s*patrÃ³n\b'
]

for pattern in nueva_intencion_patterns:
    if re.search(pattern, text_lower):
        return {
            'intent': 'nueva_intencion',
            'confidence': 0.9,
            'raw_text': text
        }
```

2. Edita `src/executor/actions.py` y agrega la acciÃ³n:

```python
elif intent == 'nueva_intencion':
    return "Respuesta para nueva intenciÃ³n"
```

### Cambiar Idioma TTS

Edita `src/main.py`:

```python
self.tts = TTSEngine(language='english')  # o 'spanish'
```

## Logging de Transcripciones

El sistema registra automÃ¡ticamente las transcripciones en:
- `logs/transcriptions.log`

Formato del log:
```
2025-10-28 22:30:45 | hola cÃ³mo estÃ¡s
2025-10-28 22:31:12 | quÃ© hora es
```

## ConfiguraciÃ³n

### ParÃ¡metros de GrabaciÃ³n

Edita la duraciÃ³n de grabaciÃ³n en `main.py`:

```python
recognizer.process_command(duration=5.0)  # 5 segundos
```

### Voz TTS

Configurar velocidad y volumen en `src/tts/tts_engine.py`:

```python
self.engine.setProperty('rate', 150)    # Velocidad (palabras/min)
self.engine.setProperty('volume', 0.9)  # Volumen (0.0-1.0)
```

## Recomendaciones y Mejores PrÃ¡cticas

### InstalaciÃ³n y ConfiguraciÃ³n
1. **Entorno Virtual**: Se recomienda crear un entorno virtual antes de instalar dependencias:
   ```bash
   python -m venv venv
   venv\Scripts\activate  # Windows
   pip install -r requirements.txt
   ```

2. **Path del Modelo**: AsegÃºrate de que el modelo de Vosk estÃ© en la estructura correcta:
   ```
   models/
   â””â”€â”€ vosk-model-small-es-0.42/
       â”œâ”€â”€ am/
       â”œâ”€â”€ conf/
       â”œâ”€â”€ graph/
       â””â”€â”€ ivector/
   ```

3. **Dependencias en Windows**: Si encuentras problemas instalando dependencias en Windows:
   - Usa `python -m pip install` en lugar de solo `pip install`
   - Verifica que estÃ©s usando la versiÃ³n correcta de Python con `python --version`

### Uso del Sistema
1. **Calidad de Audio**: Para mejores resultados:
   - Habla claramente y a una distancia de 30-50 cm del micrÃ³fono
   - Reduce el ruido de fondo
   - Usa frases completas

2. **DuraciÃ³n de GrabaciÃ³n**: Ajusta la duraciÃ³n segÃºn tus necesidades:
   - 3 segundos: Para comandos cortos (recomendado)
   - 5 segundos: Para frases mÃ¡s largas

3. **Tests**: Ejecuta los tests antes de usar el sistema:
   ```bash
   pytest tests/ -v
   ```

### Posibles Mejoras
- Agregar mÃ¡s intenciones y comandos
- Implementar reconocimiento de voz en tiempo real
- Mejorar el NLU con machine learning
- Agregar soporte multiidioma
- Implementar memoria de contexto para conversaciones

## SoluciÃ³n de Problemas

### Error: "Vosk model not loaded"
- **SoluciÃ³n**: Descarga e instala un modelo de Vosk en `models/`
- **IMPORTANTE**: AsegÃºrate de que el modelo estÃ© en la carpeta correcta: `models/vosk-model-small-es-0.42/` (con toda la estructura interna: am/, conf/, graph/, ivector/)
- **Ruta correcta**: El path debe apuntar a la carpeta especÃ­fica del modelo, no solo a `models/`

### Error: "No microphone input device found"
- **SoluciÃ³n**: Conecta un micrÃ³fono o configura el dispositivo de entrada por defecto

### Error: TTS no funciona
- **SoluciÃ³n**: El texto se imprimirÃ¡ en consola en su lugar

### Tests fallan
- **SoluciÃ³n**: AsegÃºrate de haber instalado todas las dependencias: `pip install -r requirements.txt`

### Error: "ModuleNotFoundError: No module named 'sounddevice'"
- **SoluciÃ³n**: Instala las dependencias manualmente: `python -m pip install vosk sounddevice numpy pyttsx3 cffi requests`

### Error al cargar modelo en Windows
- **SoluciÃ³n**: AsegÃºrate de usar el path completo del modelo. En Windows, el path debe ser absoluto o usar `os.path.join()` para garantizar compatibilidad
- **Ejemplo**: El cÃ³digo en `src/main.py` ya incluye la construcciÃ³n correcta del path

## Dependencias Principales

- **vosk**: Reconocimiento de voz offline
- **sounddevice**: GrabaciÃ³n y reproducciÃ³n de audio
- **pyttsx3**: SÃ­ntesis de voz offline
- **pytest**: Framework de testing

## Licencia

Este proyecto es de cÃ³digo abierto. SiÃ©ntete libre de usarlo y modificarlo.

## Autores

- **2109430** Abraham Bernacho Mares ITS
- **2127772** JosÃ© Ricardo Cruz Tapia ITS
- **2127967** Guillermo Vladimir Flores BÃ¡ez ITS

Proyecto educativo de reconocimiento de voz offline desarrollado como parte del curso de LAB 	CONTROLADORES Y MICROCONTRL. PROGRAMABLES.

## Contribuciones

Las contribuciones son bienvenidas. Para mejorar el proyecto:
1. Agrega nuevas intenciones
2. Mejora la precisiÃ³n del NLU
3. Agrega mÃ¡s tests
4. Mejora la documentaciÃ³n

---

**Nota**: Este proyecto es una simulaciÃ³n educativa. Para uso en producciÃ³n, considera sistemas mÃ¡s robustos y seguros.